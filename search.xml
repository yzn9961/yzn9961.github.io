<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>HOG特征描述子原理</title>
    <url>/2021/01/06/HOG%E7%89%B9%E5%BE%81%E6%8F%8F%E8%BF%B0%E5%AD%90/</url>
    <content><![CDATA[<h2 id="特征描述子-feature-descriptor">特征描述子( Feature Descriptor)</h2>
<p>特征描述子就是描述图像特征的一种方式，是观察图像的一种视角，这种视角能够提取出我们想要关注的特征并剔除掉多余的特征来简化图像信息。<strong>特征描述子需要尽可能的提取出图像中的有用信息</strong>。通常，特征描述子将一张大小为width×height×3 (通道数)的图片化成一个长度为n的特征向量/数组。以HOG特征为例，输入图像的大小是64×128×3，输出是一个长度为3780的特征向量。<strong>它对图像识别和目标检测这样的任务很有用。将由这些算法生成的特征向量作为支持向量机等分类算法的输入可以得到不错的结果。</strong></p>
<p>对于不同的分类任务，不同的特征对我们的分类任务是有用的，因此选择的特征描述子也不同，如：在一张图片中检测纽扣，由于纽扣通常是圆形的，所以通过对图片进行边缘检测来判断是否为纽扣是可行的。在这个例子中，边缘信息就是有用的特征，而图像的颜色信息就是冗余(无用)的特征。同时一个好的特征也要具有区分能力（如区分纽扣与车轮）。</p>
<p><strong>HOG特征描述子选择梯度方向分布作为特征，其原因在于图像的梯度包含了目标的边缘信息</strong>。一张图像的梯度(x、y方向的导数)在边缘和拐点处这类强度变化剧烈的区域幅值变化很大。而目标的边缘和拐点往往包含更多的目标信息，是我们需要关注的重点区域。</p>
<h2 id="如何计算梯度方向直方图">如何计算梯度方向直方图</h2>
<h3 id="步骤一预处理">步骤一、预处理</h3>
<figure>
<img src="https://img-blog.csdnimg.cn/img_convert/23b361b6c91f9b967f1ec1524d370444.png" alt="HOG Preprocessing" /><figcaption aria-hidden="true">HOG Preprocessing</figcaption>
</figure>
<p>在原始图像中裁减出一块图片块(patch)并修改成64*128大小，图片块作为我们的ROI区域，我们的目的就是对该区域的图片信息利用特征描述子进行描述，提取出我们感兴趣的特征。</p>
<h3 id="步骤二计算梯度图">步骤二、计算梯度图</h3>
<p>首先要计算水平和垂直方向上的梯度，此步骤可以通过下图所示的核对原图像进行滤波得到。</p>
<figure>
<img src="https://img-blog.csdnimg.cn/img_convert/974c1ffcce59416fe55f4e86840b1a2b.png" alt="Gradient Kernels" /><figcaption aria-hidden="true">Gradient Kernels</figcaption>
</figure>
<p>使用openCV中的sobel算子也能达到同样的效果，代码如下：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">// C++ gradient calculation. </span></span><br><span class="line"><span class="comment">// Read image</span></span><br><span class="line">Mat img = imread(<span class="string">&quot;bolt.png&quot;</span>);</span><br><span class="line">img.convertTo(img, CV_32F, <span class="number">1</span>/<span class="number">255.0</span>);<span class="comment">//转化为32位浮点数，顺便完成了归一化操作</span></span><br><span class="line"><span class="comment">// Calculate gradients gx, gy</span></span><br><span class="line">Mat gx, gy; </span><br><span class="line">Sobel(img, gx, CV_32F, <span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>);<span class="comment">// 只对x方向求一阶导数，且kernel大小为1</span></span><br><span class="line">Sobel(img, gy, CV_32F, <span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>); <span class="comment">//只对y方向求一阶导数</span></span><br></pre></td></tr></table></figure>
<p>关于sobel算子的简单描述参考CSDN上的两篇博客：<a href="https://blog.csdn.net/qq_37124237/article/details/82183177">sobel算子原理与实现</a>、<a href="https://blog.csdn.net/tianhai110/article/details/5663756">Sobel边缘检测算法</a></p>
<p>接下来需要计算梯度的幅度值和梯度方向(二者共同组成了该点处的梯度段)，计算公式如下： <span class="math display">\[
g = \sqrt{g^2_x+g^2_y}\\
\theta=\arctan\frac{g_y}{g_x}
\]</span> 在opencv中实现代码如下：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">// C++ Calculate gradient magnitude and direction (in degrees)</span></span><br><span class="line">Mat mag, angle; </span><br><span class="line">cartToPolar(gx, gy, mag, angle, <span class="number">1</span>); </span><br></pre></td></tr></table></figure>
<p>cartToPolar函数返回mag代表梯度幅值，angle代表梯度相角(0~<span class="math inline">\(\pi\)</span>)。具体函数信息<a href="https://docs.opencv.org/master/d2/de8/group__core__array.html#gac5f92f48ec32cacf5275969c33ee837d">参考文档</a>。</p>
<p>梯度幅值代表了该点处梯度变化的大小，梯度角代表了梯度变化最快的方向。</p>
<p>下图展示了对x方向和y方向梯度操作分别提取出的x方向边缘信息和y方向边缘信息，以及二者结合得到的总体边缘信息。</p>
<p><img src="https://blogpicbed.oss-cn-beijing.aliyuncs.com/img/20201102074537130.png" /></p>
<p>对于本例子中的图像，我们进行求梯度操作后的结果如下：</p>
<figure>
<img src="https://img-blog.csdnimg.cn/img_convert/1a66f6f597d18d769e56ad9cf81e3e1e.png" alt="Image Gradients" /><figcaption aria-hidden="true">Image Gradients</figcaption>
</figure>
<pre><code>                         左：X方向梯度幅值图；中：Y方向梯度幅值图；右：梯度幅值图</code></pre>
<p>基于梯度的HOG描述子忽略了冗余的信息(如不变的背景信息)，突出了轮廓信息，因为仅仅通过轮廓信息我们就能进行目标检测。</p>
<p>原始图像中的每一个像素都得到了该像素点处的梯度赋值和梯度角(梯度方向)信息。而对于三通道彩色图像，需要分别计算3个通道的梯度（如上图所示）。而该像素点的幅值是这3个通道梯度幅值的最大值，方向是最大梯度幅值对应的角度。</p>
<h3 id="步骤三在88的cell中计算梯度直方图">步骤三、在8×8的cell中计算梯度直方图</h3>
<p>cell操作的本质是(用梯度方向直方图)统计本cell中梯度在各个方向上的强度，该强度信息(向量)用于描述当前cell中的图像信息。</p>
<p>在本步骤中，图像将会被分割为8*8单位的很多cell，在这些cell中我们将计算梯度方向直方图。下图就是将我们的目标区域(patch)切分成数个cell的例子。</p>
<figure>
<img src="https://img-blog.csdnimg.cn/img_convert/1e3b576aa2851909c6799723aea5aa9d.png" alt="8x8 cells of HOG" /><figcaption aria-hidden="true">8x8 cells of HOG</figcaption>
</figure>
<p>那么我们首先要了解一下为什么要将图片切分成好多个8*8像素形式的cell。这个操作的本质就是对图片信息进行降维。</p>
<p>通过步骤二中的梯度计算，我们得到了每一个像素点的梯度大小以及梯度方向信息，虽然通过这些信息我们能获得目标的全部边缘信息，但是存在两点问题：</p>
<ul>
<li>维数太高：对于本例所示的ROI区域，其尺寸为<span class="math inline">\(64\times128\)</span>，其中每一个像素携带该点处梯度大小与方向两个信息，所以对于一个目标区域，我们会得到<span class="math inline">\(64\times128\times2=16284\)</span>维的向量(我们将所有像素信息依次排列成一个向量)，向量维数太高，运算成本太昂贵。</li>
<li>某些像素点携带的信息是错误的：图像中存在噪点，对于这些噪点我们需要剔除。</li>
</ul>
<p>综合上述两点我们希望能找到一种方式，其具有下述特征：</p>
<ol type="1">
<li>降低维度：能否将多个像素的信息凝炼到一个新的单位中？即创造一个新的基本单位a来携带多个像素的信息。</li>
<li>降低对噪点的敏感性：对于噪点其梯度幅值和方向都是错误的，虽然对于单一的像素点这种偏差是显著的，但从一个大范围的统计学角度来看来看(如统计8*8=64像素的单元格内的梯度-角度分布累计特性)，这种单一样本造成的偏差是不明显的。</li>
</ol>
<p>综上，我们创造了一种新的图像基本单位cell，一个cell对应原图像的一个8*8像素区，一个cell对应64个像素信息，这样可以起到很好的降维作用。由pixel向cell转换的方式采用基于统计学的梯度(幅值)-(梯度)方向直方图，这样对一个<span class="math inline">\(8\times8\)</span>区域的统计操作可以降低算法对噪点的敏感度。而选择一个<span class="math inline">\(8\times8\)</span>区域作为一个cell的原因在于，HOG描述子最初被用于行人检测，8×8的cell在一张64×128的行人图片块中的足以捕捉感兴趣的特征（如人脸、头顶等），当然cell尺寸的选择可以根据目标的不同而改变。</p>
<p>在规定完成cell的尺寸之后，我们详细讲解一下用一个cell表征64个pixel信息的方法——梯度方向直方图。</p>
<p>首先，我们观察一下在划分cell之后，每个cell中包含的梯度幅度/相角信息，以运动员头部的cell为例：</p>
<figure>
<img src="https://img-blog.csdnimg.cn/img_convert/6a51adda899dd31b632cb26c980abe06.png" alt="HOG Cell Gradients" /><figcaption aria-hidden="true">HOG Cell Gradients</figcaption>
</figure>
<p>中间红色框选的区域十分清晰的描述了一个cell中每个元素同时携带的梯度幅值与方向信息——<strong>箭头的指向表示了梯度的方向而箭头的长度表示了梯度的大小。箭头的长短表明了该点处图像强度的变化大小，而箭头的方向指向了该点处强度变化最大的方向。</strong></p>
<p>在右上角的梯度幅值图中我们可以发现位于目标边缘的像素梯度值更大，而背景区以及目标内部的梯度值更小。而对于右下角的梯度相角图，我们发现其值域位于[0~180]而非中间图的 [0~360]，这种表述方式将方向相反的两个梯度(角)方向表述为同一个梯度方向，这种方式叫做“无符号梯度”，根据经验，无符号梯度表示法比有符号梯度效果更好。一些HOG的实现代码会允许你选择是否使用有符号梯度。</p>
<p>在直观的观察完每个cell中的像素信息之后，我们根据上图右侧梯度幅值图和梯度方向图创建统计直方图，而创建这个直方图的目的在于：我们希望统计出在一个cell中梯度在某几个方向上的分布累计值，用梯度在这几个方向上的累计分布情况来替代64个像素携带的梯度值-梯度角信息，从而完成图像基本单位从pixel——&gt;cell的转换。</p>
<p>我们以梯度方向角为x轴，并且取值为离散的0°、20°、40°、… 160°共计9个方向值。梯度累计值为y轴，而梯度累计值采用加权累加的方法进行，过程如下：</p>
<figure>
<img src="https://img-blog.csdnimg.cn/img_convert/ed45e94b160de5c4e3b036fe04174fd3.png" alt="Histogram computation in HOG" /><figcaption aria-hidden="true">Histogram computation in HOG</figcaption>
</figure>
<p>对于蓝圈中的像素，其梯度方向为80，其梯度值为2，所以在梯度分布直方图的80坐标处加上2即可。对于红圈中的像素，其梯度方向为10度，位于0-20正中间，所以该像素所对应的梯度以1：1加权，一分为二分配到0与20的直方图横坐标上。</p>
<p>下图是一个更具普遍性的例子：</p>
<figure>
<img src="https://img-blog.csdnimg.cn/img_convert/c89aa46fe34ac8477fb29ee0395ae44e.png" alt="Histogram computation in HOG" /><figcaption aria-hidden="true">Histogram computation in HOG</figcaption>
</figure>
<p>上图所示的像素梯度角为<span class="math inline">\(165^{\circ}\)</span>,梯度值为<span class="math inline">\(85\)</span>。对于大于160度的梯度角，他们实际是位于0度和160度之间，我们将该像素点处的梯度信息按照如下形式加权分配到0刻度与160刻度上： <span class="math display">\[
\text{for 0 : }\ \ \ \frac{165-160}{20}\times85=21.25\\
\text{for 160 : }\ \ \ \frac{180-165}{20}\times85=63.75\\
\]</span> 最终，将8×8的cell中所有像素处的梯度按照方向将梯度大小累加到9个bin以创建最后的梯度直方图。该直方图概括了该cell中梯度值在9个方向上的统计特征(分布特性)。</p>
<p>上图中的cell对应的梯度直方图如下</p>
<figure>
<img src="https://img-blog.csdnimg.cn/img_convert/91d0c8fc91fa3337daa671abc628690d.png" alt="Histogram of 8x8 cell" /><figcaption aria-hidden="true">Histogram of 8x8 cell</figcaption>
</figure>
<p>观察这个直方图我们发现，这个cell中的梯度方向在0或180度附近分布的权重最大，这从另外一个角度说明了在这个cell中大部分梯度方向要么朝上要么朝下。到此，我们可以用一个包含九个元素的向量来描述一个cell中的梯度分布情况。</p>
<h3 id="步骤四1616-block标准化">步骤四、16×16 Block标准化</h3>
<p>直方图标准化就是对在更大尺度上对直方图向量信息标准化一下，目的是消除光照的影响。</p>
<p>光照对图片的影响可分为两种：一种是亮度变化，体现为像素强度值的加性偏移；另一种则是对比度变化，体现为像素强度值的乘性偏移。对于亮度变化，由于他对像素值的变化是加性的，所以对图像梯度的影响不大。而对于对像素强度进行乘性操作的对比度变化，图像梯度值会受到很大的影响。因此需要削图像对比度的影响。标准化可以消除对比度的影响。我们采用L2范数(曼哈顿距离)来对图像进行标准化操作。L2范数的详细内容请参考：<a href="https://blog.csdn.net/fantacy10000/article/details/90647686?utm_medium=distribute.pc_relevant_t0.none-task-blog-BlogCommendFromMachineLearnPai2-1.edu_weight&amp;depth_1-utm_source=distribute.pc_relevant_t0.none-task-blog-BlogCommendFromMachineLearnPai2-1.edu_weight">这篇博客</a></p>
<p>在HOG中我们选择在一个更大的尺度上进行标准化操作，我们划分出一个<span class="math inline">\(16*16\)</span>的block，这个block中包含<span class="math inline">\(2*2=4\)</span>个cell。对于每个cell我们可以把它看作一个九元素的向量，将这些元素按照向量顺序依次排序，我们针对于一个block就可以获得<span class="math inline">\(4*9=36\)</span>个元素的向量，我们对该36元向量进行L2标准化即可。同时，我们以16*16元素作为一个窗口，以8pixels作为步长来滑动窗口，对窗口区域内的cell进行标准化。如下图所示： <img src="https://img-blog.csdnimg.cn/20201103092253469.gif#pic_center" alt="在这里插入图片描述" /></p>
<h3 id="步骤五计算hog特征向量">步骤五、计算HOG特征向量</h3>
<p>本步骤其实就是将整个图片patch中的block中的直方图向量信息连接起来就行了。</p>
<p>将标准化后的直方图中包含的向量信息按照顺序(从左到右、从上到下)连接起来即可得到输入SVM分类器的样本向量。我们计算以下经过上述步骤后的样本区域向量维度。首先我们已知一个block的向量长度是36，而一张<span class="math inline">\(64*128\)</span>像素的图像包含 (64-8)/8=7 个水平的位置和 (128-8)/8=15 个竖直的位置，总计7×15=105个block。所以样本区的向量长度最终可以表征为一个36*105=3780维度的向量。相比于原来的16284维向量维数降低了=77%，起到了很好的降维效果。</p>
<p>至此我们得到了通过HOG特征描述子描述的目标样本区域。我们可以看出HOG描述子本身并没有对图像进行检测、分配、匹配等操作，仅仅是对图像强度信息进行运算，得到了一个用以描述样本区域某个特征(在HOG中是边缘)的向量(特征描述子)。再次印证了开篇对特征描述子的定义：特征描述子就是描述图像特征的一种方式，是观察图像的一种视角。</p>
<p>HOG行人检测的后续部分将在SVM分类器中进行。</p>
]]></content>
      <categories>
        <category>计算机视觉</category>
      </categories>
      <tags>
        <tag>HOG特征</tag>
        <tag>行人检测</tag>
      </tags>
  </entry>
  <entry>
    <title>相机标定学习笔记(一)：单目标定</title>
    <url>/2020/12/30/%E6%91%84%E5%83%8F%E6%9C%BA%E6%A0%87%E5%AE%9A/</url>
    <content><![CDATA[<h2 id="一相机标定理论概述">一、相机标定理论概述</h2>
<h3 id="什么是相机标定">1.1 什么是相机标定</h3>
<p>获取相机参数的过程称之为计算机标定。相机参数分为内参与外参：</p>
<ul>
<li><strong>相机内参</strong>：即镜头本身的参数，包含焦距、缩放比例(像素在世界坐标系中的尺寸)、镜头畸变参数等。</li>
<li><strong>相机外参</strong>：即外部参数矩阵，是联系摄像机坐标系与世界坐标系之间的桥梁，将摄像机坐标系中的点的位置坐标转化为世界坐标系中点的坐标。外部参数矩阵中包含了镜头的在三维空间中的位置信息以及角度信息(水平偏转、垂直俯仰、法平面旋转)。世界/相机坐标系定义<a href="https://www.learnopencv.com/geometry-of-image-formation/">参考</a>。</li>
<li><strong>内参、外参、世界坐标系、相机坐标系之间的联系</strong>：位于<strong>世界坐标系</strong>中的目标坐标通过相机<strong>外参矩阵</strong>转换到<strong>相机坐标系</strong>中，再通过<strong>内参矩阵</strong>投射到<strong>图像平面</strong>上。</li>
</ul>
<p>通过获取相机的内外参，<strong>我们可以将目标在世界坐标系中的三维坐标信息转换为图像平面上的像素位置</strong>。换言之，获取了相机的内外参数我们就可以模拟出一个相机的数学模型。</p>
<figure>
<img src="https://www.learnopencv.com/wp-content/uploads/2020/02/camera-projection-3D-to-2D.png" alt="Camera Projection from 3D to 2D" /><figcaption aria-hidden="true">Camera Projection from 3D to 2D</figcaption>
</figure>
<h3 id="相机标定的意义">1.2 相机标定的意义</h3>
<p>通过获取摄像机的参数来对图像进行矫正，从而减小图像上的畸变。</p>
<figure>
<img src="https://www.learnopencv.com/wp-content/uploads/2019/11/geometric-calibration-1024x381.jpg" alt="Correction after geometric calibration" /><figcaption aria-hidden="true">Correction after geometric calibration</figcaption>
</figure>
<h3 id="相机标定原理">1.3 相机标定原理</h3>
<p>如上文所述，借由相机的内外参，我们可以完成目标点在现实世界中的三维坐标与在图像平面上的像素位置的相互转换。相机标定的原理与上述过程相反：<strong>我们已知一组点集在现实中的三维坐标，以及它们在图像平面上的像素位置，通过数学方法求出两组坐标系之间的转换关系——即相机的内外参数</strong>。</p>
<ul>
<li><strong>相机标定的输入</strong>：多张包含关键点的图像。对于该组图像上的关键点，我们知道它们位于现实世界的实际坐标以及其投射在图像平面上的像素位置。</li>
<li><strong>相机标定的输出</strong>：相机的内外参数矩阵。</li>
</ul>
<h3 id="相机标定流程">1.4 相机标定流程</h3>
<p>相机标定大致按照以下几个流程进行：</p>
<ul>
<li><strong>建立标定数据集：</strong>我们需要收集一组图像，每张图像中包含一组已知其在真实世界中三维坐标的关键点。</li>
<li><strong>在图像上定位关键点：</strong>查找出关键点在图像平面上对应的像素位置信息。</li>
<li><strong>标定相机内外参：</strong>通过opencv的相机标定函数，计算出相机的内外参数。</li>
<li><strong>畸变矫正：</strong>通过相机参数矫正图像上的畸变。</li>
</ul>
<p><img src="https://www.learnopencv.com/wp-content/uploads/2020/02/camera-calibration-flowchart-1024x910.png" alt="Camera Calibration Flowchart" style="zoom: 45%;" /></p>
<h2 id="二相机标定实践获取双目摄像头两个镜头的内外参">二、相机标定实践：获取双目摄像头两个镜头的内外参</h2>
<p>我们按照上述流程来对下图所示型号双目摄像头进行标定。我们在基于opencv3.4.2的环境下使用c++进行实现。</p>
<p><img src="https://blogpicbed.oss-cn-beijing.aliyuncs.com/img/image-20201223144024650.png" alt="FotoJet" style="zoom: 25%;" /></p>
<h3 id="标定数据集的建立">2.1 标定数据集的建立</h3>
<h4 id="棋盘格标定板">2.1.1 棋盘格标定板</h4>
<p>进行相机标定时一般采用张正友标定法来对关键点进行选择。张正友标定法采用一张黑白相间的棋盘格图像作为相机标定的标定板，在进行标定时，该方法会提取棋盘格标定板的内角点集作为关键点集，如下图所示：</p>
<p><img src="https://www.learnopencv.com/wp-content/uploads/2019/11/checkerboard-pattern-detection2.jpg" alt="Result after drawing the detected checker board corners" style="zoom: 67%;" /></p>
<p>在本次标定中，我们使用的标定板图像如下图所示。我们可以观察到，该标定板图像纵向有6个内角点作为标定关键点，横向有9个内角点作为标定关键点。</p>
<p><img src="https://blogpicbed.oss-cn-beijing.aliyuncs.com/img/pattern.jpg" alt="image-20201223144024650" style="zoom: 35%;" /></p>
<h4 id="从多个角度拍摄标定板图像">2.1.2 从多个角度拍摄标定板图像</h4>
<p>为了计算出相机的内外参数我们需要多组包含关键点信息的数据集，故我们需要从多个角度对标定板进行拍摄，获取多个角度的标定板图像。下图是从多个角度拍摄的标定板数据集。数据集中的照片数量越多，计算越精确但同时计算开销也越大。这里我使用双目摄像头从不同角度拍摄了39张照片作为标定数据集。</p>
<figure>
<img src="https://blogpicbed.oss-cn-beijing.aliyuncs.com/img/image-20201223213014521.png" alt="image-20201223232837530" /><figcaption aria-hidden="true">image-20201223232837530</figcaption>
</figure>
<p>使用双目摄像头进行拍照，并将左右摄像头拍摄的图像分别存储程序的部分代码如下：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function">VideoCapture <span class="title">cap</span><span class="params">(<span class="number">0</span>)</span></span>;</span><br><span class="line">	<span class="keyword">if</span> (!cap.isOpened())</span><br><span class="line">	&#123;</span><br><span class="line">		<span class="built_in">cout</span> &lt;&lt; <span class="string">&quot;摄像头读取错误!&quot;</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">		<span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="comment">//设置捕获视频尺寸</span></span><br><span class="line">	<span class="keyword">char</span> filename[<span class="number">200</span>];</span><br><span class="line">	cap.<span class="built_in">set</span>(CAP_PROP_FRAME_WIDTH, <span class="number">2560</span>); </span><br><span class="line">	cap.<span class="built_in">set</span>(CAP_PROP_FRAME_HEIGHT,<span class="number">720</span>);</span><br><span class="line">	<span class="keyword">int</span> i =<span class="number">1</span>;</span><br><span class="line">	<span class="built_in">string</span> name;</span><br><span class="line">	<span class="built_in">cout</span> &lt;&lt; <span class="string">&quot;拍照模式：按空格键进行拍摄。q 或 Esc 退出。&quot;</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">	<span class="built_in">string</span> window_name = <span class="string">&quot;拍照模式：按空格键进行拍摄 | q 或 Esc 退出&quot;</span>;</span><br><span class="line">	namedWindow(window_name,WINDOW_NORMAL); <span class="comment">//not resizable window;</span></span><br><span class="line">	Mat frameTotal;</span><br><span class="line">	<span class="comment">//Rect Total(0, 150, 640, 180);//全画幅</span></span><br><span class="line">	<span class="function">Rect <span class="title">Lrect</span><span class="params">(<span class="number">0</span>,<span class="number">0</span>, <span class="number">2560</span>/<span class="number">2</span>,<span class="number">720</span>)</span></span>;<span class="comment">//左ROI</span></span><br><span class="line">	<span class="function">Rect <span class="title">Rrect</span><span class="params">(<span class="number">2560</span> / <span class="number">2</span>, <span class="number">0</span>, <span class="number">2560</span>/<span class="number">2</span>, <span class="number">720</span>)</span></span>; <span class="comment">//右ROI</span></span><br><span class="line">	<span class="keyword">while</span> (<span class="number">1</span>)</span><br><span class="line">	&#123;</span><br><span class="line">		cap &gt;&gt; frameTotal;</span><br><span class="line">		imshow(<span class="string">&quot;拍照模式：按空格键进行拍摄 | q 或 Esc 退出&quot;</span>, frameTotal);</span><br><span class="line">		<span class="keyword">char</span> key = (<span class="keyword">char</span>)waitKey(<span class="number">30</span>);</span><br><span class="line">		<span class="keyword">switch</span> (key)</span><br><span class="line">		&#123;</span><br><span class="line">		<span class="keyword">case</span><span class="number">&#x27;</span>q<span class="number">&#x27;</span>:</span><br><span class="line">		<span class="keyword">case</span><span class="number">&#x27;</span>Q<span class="number">&#x27;</span>:</span><br><span class="line">		<span class="keyword">case</span> <span class="number">27</span>:</span><br><span class="line">			<span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">		<span class="keyword">case</span> <span class="string">&#x27; &#x27;</span>:</span><br><span class="line">			sprintf_s(filename, <span class="string">&quot;Capture_%d.jpg&quot;</span>, i);</span><br><span class="line">			imwrite(filename, frameTotal);<span class="comment">//保存全画幅</span></span><br><span class="line">			sprintf_s(filename, <span class="string">&quot;L_%d.jpg&quot;</span>, i);</span><br><span class="line">			imwrite(filename, frameTotal(Lrect));<span class="comment">//保存左画幅</span></span><br><span class="line">			sprintf_s(filename, <span class="string">&quot;R_%d.jpg&quot;</span>, i);</span><br><span class="line">			imwrite(filename, frameTotal(Rrect));<span class="comment">//保存右画幅</span></span><br><span class="line">			<span class="built_in">cout</span> &lt;&lt; <span class="string">&quot;捕捉到第&quot;</span>&lt;&lt;i&lt;&lt;<span class="string">&quot;组图像&quot;</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">			i++;</span><br><span class="line">		<span class="keyword">default</span>:</span><br><span class="line">			<span class="keyword">break</span>;</span><br><span class="line">		&#125;</span><br><span class="line">		</span><br><span class="line">	&#125;</span><br></pre></td></tr></table></figure>
<p>需要注意的是，<strong>在制作标定板的过程中一定要在标定板周围留出足够宽(越宽越好)的白边</strong>，否则opencv将无法检测出标定板上的关键点，从而标定失败。这是因为当棋盘格标定板外侧无白边或是拍摄背景为黑色时，下文将会用到的关键点定位函数<code>findChessboardCorners()</code>内部的分组与排序算法将会失效。所以<strong>标定板周围需要留出足够宽的白边，同时不要在黑暗的背景环境下拍摄</strong>。下图是我使用ipad作为标定板拍摄的标定照片，可以看出标定图像并没有占据整个屏幕，而是留出了一定空余的白边。</p>
<p><img src="https://blogpicbed.oss-cn-beijing.aliyuncs.com/img/R_1.jpg" alt="pattern" style="zoom: 50%;" /></p>
<h4 id="确定关键点在真实世界中的三维坐标">2.1.3 确定关键点在真实世界中的三维坐标</h4>
<p>由理论部分我们已经知道，标定出相机的内外参数需要同时确定出关键点<strong>在真实世界的三维坐标</strong>以及<strong>在图像平面上的像素位置</strong>。在这一步我们对第一个问题进行解决。关键点在真实世界的三维坐标<strong>是人为规定的</strong>。观察下图所示的棋盘格标定板，我们规定墙面为三维坐标系中的x-y平面，指向地面方向为x轴，水平向右方向为y轴，而z轴则位于垂直于墙面的方向。显然，为了简化操作，我们将所有关键点的z轴坐标都设置为0，即将所有关键点都放置于x-y平面上。</p>
<p><img src="https://www.learnopencv.com/wp-content/uploads/2020/02/image_2.jpg" alt="Checkerboard pattern " style="zoom: 60%;" /></p>
<p>使用棋盘格标定板进行标定的一个优点在于所有关键点之间的水平/竖直间隔均一致，故在我们人为规定一个关键点的三维坐标信息后，可以简便的迭代计算出其余关键点在真实世界中的三维坐标信息。6*9内角点标定板的关键点坐标信息输入程序如下：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">int</span> CHESSBOARD[<span class="number">2</span>] = &#123; <span class="number">6</span>,<span class="number">9</span> &#125;;</span><br><span class="line"><span class="built_in">vector</span>&lt;Point3f&gt;objp;<span class="comment">//存储关键点的真实三维坐标信息</span></span><br><span class="line">	<span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; CHESSBOARD[<span class="number">1</span>]; i++)</span><br><span class="line">	&#123;</span><br><span class="line">		<span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; CHESSBOARD[<span class="number">0</span>]; j++)</span><br><span class="line">			objp.push_back(Point3f(i, j, <span class="number">0</span>));<span class="comment">//逐行标记内角点坐标</span></span><br><span class="line">	&#125;</span><br></pre></td></tr></table></figure>
<h3 id="确定关键点在图像平面上的位置">2.2 确定关键点在图像平面上的位置</h3>
<p>通过第一步的操作我们获得了一组从多角度拍摄的标定板图像作为我们的标定数据集，同时对于数据集中的关键点集我们人为的规定了其在真实世界的三维坐标信息，我们最后需要确定的是这些关键点在各个图片上的二维像素坐标。</p>
<h4 id="在图像上定位关键点的像素位置">2.2.1 在图像上定位关键点的像素位置</h4>
<p>在图像上定位关键点我们直接使用opencv内置的函数实现<code>findChessboardCorners()</code>，该函数原型如下：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">bool</span> <span class="title">cv::findChessboardCorners</span>	<span class="params">(InputArray image,</span></span></span><br><span class="line"><span class="function"><span class="params">								Size 	patternSize,</span></span></span><br><span class="line"><span class="function"><span class="params">								OutputArray 	corners,</span></span></span><br><span class="line"><span class="function"><span class="params">								<span class="keyword">int</span> 	flags </span></span></span><br><span class="line"><span class="function"><span class="params">								)</span>	</span></span><br></pre></td></tr></table></figure>
<ul>
<li><strong>InputArray image：</strong>输入图像</li>
<li><strong>Size patternSize：</strong>标定板尺寸，我使用的标定板尺寸是6*9格式</li>
<li><strong>OutputArray：</strong>检测到的关键点坐标集合，类型为<code>vector&lt;Point2f&gt;</code></li>
<li><strong>int flags:</strong> 算法的其他参数，一般选择默认值<code>CALIB_CB_ADAPTIVE_THRESH + CALIB_CB_NORMALIZE_IMAGE + CALIB_CB_FAST_CHECK</code>即可。</li>
</ul>
<p>该算法会在每张图片上检索以<code>patternSize</code>格式(对于我的标定板该值是6 * 9)排布的关键点集，若无法完整的检测出一组以 6 * 9格式排布的关键点集，则函数返回布尔值为0，反之若完整的检测出标定板上的关键点集合，则返回一个非零布尔值。</p>
<h4 id="使用亚像素精准化关键点坐标位置">2.2.2 使用亚像素精准化关键点坐标位置</h4>
<p>由于相机标定对于数据精准度的要求很高，为了进一步提升我们标定结果的精准度，我们需要在<strong>亚像素</strong>层面对关键点坐标进一步精确化。</p>
<blockquote>
<p><strong>什么是亚像素？</strong>我们获取到的图像是由无数个离散的像素组成，每一个像素点只代表其附近的颜色。而在某些精确化计算的场景下，以像素为单位所能达到的图像精度无法满足场景要求，这时我们通过对相邻两个像素进行插值运算，来获得<strong>两个像素之间某个位置的颜色值，该位置便被称为亚像素</strong>。在图像测量中经常会出现亚像素，如测量某个圆的直径为100.12像素，0.12就是亚像素。</p>
</blockquote>
<p>同样我们使用opencv的函数实现<code>cornerSubPix</code>来精确化关键点坐标信息，函数原型如下：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">cv::cornerSubPix</span>	<span class="params">(InputArray 	image,</span></span></span><br><span class="line"><span class="function"><span class="params">						InputOutputArray 	corners,</span></span></span><br><span class="line"><span class="function"><span class="params">						Size 	winSize,</span></span></span><br><span class="line"><span class="function"><span class="params">						Size 	zeroZone,</span></span></span><br><span class="line"><span class="function"><span class="params">						TermCriteria 	criteria </span></span></span><br><span class="line"><span class="function"><span class="params">						)</span>	</span></span><br></pre></td></tr></table></figure>
<ul>
<li><p><strong>InputArray image:</strong> 输入图像</p></li>
<li><p><strong>InputOutputArray corners：</strong> 类型为<code>vector&lt;Point2f&gt;</code>的关键点集合，包含了关键点的坐标信息，使用亚像素精确化后会对该集合进行刷新</p></li>
<li><p><strong>Size winSize：</strong>填写默认值<code>Size(11, 11)</code>即可</p></li>
<li><p><strong>Size zeroZone：</strong>填写默认值<code>Size(-1, -1)</code>即可</p></li>
<li><p><strong>TermCriteria criteria :</strong> 迭代终止条件。由于<code>cornerSubPix()</code>函数是依靠迭代完成的，所以我们需要人为的设置迭代终止条件。opencv中提供了专门的迭代终止条件类<code>TermCriteria</code>，该类提供了两种类型的迭代终止条件：完成最大迭代次数停止<code>MAX_ITER</code>、满足迭代精度停止<code>EPS</code>。在本问题中，我们希望二者满足其一即可停止迭代，故我们按照如下格式设置迭代终止条件。</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function">cv::TermCriteria <span class="title">criteria</span><span class="params">(cv::TermCriteria::EPS | cv::TermCriteria::MAX_ITER, <span class="number">30</span>, <span class="number">0.001</span>)</span></span>;</span><br></pre></td></tr></table></figure>
<p>可见迭代达次数到30次或迭代精度达到0.001二者满足其义即可结束迭代。</p></li>
</ul>
<h4 id="可选在图像上绘制关键点">2.2.3 (可选)在图像上绘制关键点</h4>
<p>为了更直观的查看关键点在每一张图片上的位置，我们可以将关键点逐个绘制出来。opencv中也提供了相应的函数实现<code>drawChessboardCorners()</code>，函数原型如下：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">cv::drawChessboardCorners</span>	<span class="params">(InputOutputArray 	image,</span></span></span><br><span class="line"><span class="function"><span class="params">								Size 	patternSize,</span></span></span><br><span class="line"><span class="function"><span class="params">								InputArray 	corners,</span></span></span><br><span class="line"><span class="function"><span class="params">								<span class="keyword">bool</span> 	patternWasFound </span></span></span><br><span class="line"><span class="function"><span class="params">							  )</span>	</span></span><br></pre></td></tr></table></figure>
<ul>
<li><strong>InputOutputArray image:</strong> 输入/输出图像</li>
<li><strong>Size patternSize：</strong>标定板的排布样式，同上文，我们使用6*9排布格式的标定板</li>
<li><strong>InputArray corners：</strong>检测到的关键点集</li>
<li><strong>bool patternWasFound ：</strong>该处填写<code>findChessboardCorners()</code>函数的布尔返回值，对于检测到全部关键点的图像，函数将会使用连线将关键点进行连接；对于没有检测出全部关键点的图像，函数只会标记处检测出的关键点位置。</li>
</ul>
<p>最终绘图效果如下图所示，可以看出我们已经检测出了全部关键点并使用彩虹色将他们依次进行了连接。</p>
<figure>
<img src="https://blogpicbed.oss-cn-beijing.aliyuncs.com/img/image-20201223230933744.png" alt="black_edge" /><figcaption aria-hidden="true">black_edge</figcaption>
</figure>
<h3 id="标定摄像头内外参">2.3 标定摄像头内外参</h3>
<p>通过上述操作，我们已经获得了关键点在真实世界的三维坐标以及在图像平面上的二维坐标信息，我们将二者作为输入，调用opencv中的<code>calibrateCamera()</code>函数实现即可计算出摄像头的内外参数。<code>calibrateCamera()</code>的函数原型如下：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">double</span> <span class="title">cv::calibrateCamera</span>	<span class="params">(InputArrayOfArrays objectPoints,</span></span></span><br><span class="line"><span class="function"><span class="params">							InputArrayOfArrays 	imagePoints,</span></span></span><br><span class="line"><span class="function"><span class="params">							Size 	imageSize,</span></span></span><br><span class="line"><span class="function"><span class="params">							InputOutputArray 	cameraMatrix,</span></span></span><br><span class="line"><span class="function"><span class="params">							InputOutputArray 	distCoeffs,</span></span></span><br><span class="line"><span class="function"><span class="params">							OutputArrayOfArrays 	rvecs,</span></span></span><br><span class="line"><span class="function"><span class="params">							OutputArrayOfArrays 	tvecs,</span></span></span><br><span class="line"><span class="function"><span class="params">						   )</span>	</span></span><br></pre></td></tr></table></figure>
<ul>
<li><strong>InputArrayOfArrays objectPoints:</strong> 关键点在真实世界中的三维坐标集合</li>
<li><strong>InputArrayOfArrays imagePoints：</strong>关键点在图像平面上的二维坐标集合</li>
<li><strong>Size imageSize</strong>：图像尺寸信息</li>
<li><strong>InputOutputArray cameraMatrix</strong>：输出摄像机内参矩阵</li>
<li><strong>InputOutputArray distCoeffs:</strong> 输出镜头畸变系数向量</li>
<li><strong>OutputArrayOfArrays rvecs：</strong>相机旋转矩阵，外参之一</li>
<li><strong>OutputArrayOfArrays tvecs：</strong>相机偏移矩阵，外参之一</li>
</ul>
<p>调用上述函数将会计算出相机的内外参数，计算时长取决于标定数据集中的图像数量，最终我们得到了相机的内外参数如下图所示：</p>
<figure>
<img src="https://blogpicbed.oss-cn-beijing.aliyuncs.com/img/image-20201223232837530.png" alt="image-20201223213014521" /><figcaption aria-hidden="true">image-20201223213014521</figcaption>
</figure>
<p>我们注意到相机外参矩阵维数很大，这是由于每一张图片中相机与标定板之间的相对位置不同，故代表两者位置关系的相机外参也不同，每一张图片的外参都会单独计算。而在相机畸变矫正中我们不需要使用到相机与目标之间的位置关系，故我们只是用相机内参对图像进行矫正即可，即我们仅关注<code>cameraMatrix</code>与<code>distCoeffs</code>两个变量。</p>
<h3 id="畸变矫正">2.4 畸变矫正</h3>
<p>对图像的畸变进行矫正有两种实现，两种实现的输入均相同，下面分别对两种方法进行介绍。</p>
<h4 id="使用initundistortrectifymapremap实现">2.4.1 使用<code>initUndistortRectifyMap()</code>+<code>remap()</code>实现</h4>
<p>该方法的代码如下：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line">cv::initUndistortRectifyMap(cameraMatrix, distCoeffs, cv::Mat(),</span><br><span class="line">                            cv::getOptimalNewCameraMatrix(cameraMatrix, </span><br><span class="line">                                                          distCoeffs,   </span><br><span class="line">                                                          imageSize, <span class="number">1</span>, </span><br><span class="line">                                                          imageSize,<span class="number">0</span>),</span><br><span class="line">                            imageSize, CV_16SC2, map1, map2);</span><br><span class="line">cv::remap(frame, dst, map1, map2, cv::INTER_LINEAR);</span><br></pre></td></tr></table></figure>
<p>该部分代码只做功能性的介绍：<code>cameraMatrix</code>与 <code>distCoeffs</code>代表相机内参，<code>imageSize</code>代表图像尺寸，通过<code>cv::getOptimalNewCameraMatrix</code>函数来选择矫正后的图像是否保留畸变矫正所产生的黑色边缘，<code>map1</code>与<code>map2</code>则代表了<code>remap()</code>函数所需要的畸变坐标映射矩阵，作为<code>remap()</code>函数的输入。</p>
<p>下图展示了是否保留黑色边缘对图像的影响，左图是保留黑边的效果图，右图则是剔除黑边后的图像。可以观察到如果保留黑边则原始图像的全部像素信息都会被保留，但是图像边缘会包含黑色的无用像素区域。而右图所示的剔除黑边效果图实际上只是在左图的基础上按照原始图像的比例对非黑色区域进行了裁剪，虽然去除了黑边，但是会损失位于角落的像素信息。</p>
<p><img src="https://blogpicbed.oss-cn-beijing.aliyuncs.com/img/black_edge.jpg" alt="R_1"  /></p>
<h4 id="使用cvundistort实现">2.4.2 使用<code>cv::undistort()</code>实现</h4>
<p>该方法实现代码如下：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line">cv::new_camera_matrix;</span><br><span class="line">new_camera_matrix = cv::getOptimalNewCameraMatrix(cameraMatrix, distCoeffs, imageSize, <span class="number">1</span>, imageSize, <span class="number">0</span>);</span><br><span class="line">cv::undistort( frame, dst, new_camera_matrix, distCoeffs, new_camera_matrix );</span><br></pre></td></tr></table></figure>
<p>本质上是 <code>initUndistortRectifyMap()</code>与<code>remap()</code>两个函数的封装，最终的矫正效果是相同的。但是从效率层面上讲，由于<code>remap()</code>函数需要调用 <code>initUndistortRectifyMap()</code>函数计算得到的两个参量<code>map1</code>与<code>map2</code>，对同一镜头拍摄的多张畸变图像进行矫正时，畸变坐标映射矩阵<code>map1</code>与<code>map2</code>计算一次即可，此时若使用<code>cv::undistort()</code>进行畸变矫正则会反复计算<code>map1</code>与<code>map2</code>，影响程序效率。因此当需要矫正的畸变图像很多时，调用一次<code>initUndistortRectifyMap()</code>统一计算出畸变坐标映射矩阵<code>map1</code>与<code>map2</code>，然后反复调用<code>remap()</code>函数进行畸变矫正即可。</p>
<h4 id="畸变矫正效果展示">2.4.3 畸变矫正效果展示</h4>
<p>对于数据集中的一张图像进行畸变矫正，总体效果如下</p>
<p><img src="https://blogpicbed.oss-cn-beijing.aliyuncs.com/img/FotoJet.jpg" alt="image-20201223230933744"  /></p>
<p><strong>输入的原始图像</strong></p>
<figure>
<img src="https://blogpicbed.oss-cn-beijing.aliyuncs.com/img/左镜头原始图像.jpg" alt="左镜头原始图像" /><figcaption aria-hidden="true">左镜头原始图像</figcaption>
</figure>
<p><strong>保留黑色边缘的矫正图像</strong></p>
<figure>
<img src="https://blogpicbed.oss-cn-beijing.aliyuncs.com/img/畸变矫正(保留黑边).jpg" alt="畸变矫正(保留黑边)" /><figcaption aria-hidden="true">畸变矫正(保留黑边)</figcaption>
</figure>
<p><strong>剔除黑色边缘后的矫正图像</strong></p>
<figure>
<img src="https://blogpicbed.oss-cn-beijing.aliyuncs.com/img/畸变矫正(剔除黑边).jpg" alt="畸变矫正(剔除黑边)" /><figcaption aria-hidden="true">畸变矫正(剔除黑边)</figcaption>
</figure>
<h2 id="三程序代码">三、程序代码</h2>
<h3 id="图像采集代码">图像采集代码</h3>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;opencv2/opencv.hpp&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;opencv2/highgui/highgui.hpp&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> cv;</span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;	</span><br><span class="line">	<span class="function">VideoCapture <span class="title">cap</span><span class="params">(<span class="number">0</span>)</span></span>;</span><br><span class="line">	<span class="keyword">if</span> (!cap.isOpened())</span><br><span class="line">	&#123;</span><br><span class="line">		<span class="built_in">cout</span> &lt;&lt; <span class="string">&quot;摄像头读取错误!&quot;</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">		<span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="comment">//获取视频尺寸</span></span><br><span class="line">	<span class="keyword">char</span> filename[<span class="number">200</span>];</span><br><span class="line">	cap.<span class="built_in">set</span>(CAP_PROP_FRAME_WIDTH, <span class="number">2560</span>); </span><br><span class="line">	cap.<span class="built_in">set</span>(CAP_PROP_FRAME_HEIGHT,<span class="number">720</span>);</span><br><span class="line">	<span class="keyword">int</span> i =<span class="number">1</span>;</span><br><span class="line">	<span class="built_in">string</span> name;</span><br><span class="line">	<span class="built_in">cout</span> &lt;&lt; <span class="string">&quot;拍照模式：按空格键进行拍摄。q 或 Esc 退出。&quot;</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">	<span class="built_in">string</span> window_name = <span class="string">&quot;video | q or esc to quit&quot;</span>;</span><br><span class="line">	namedWindow(window_name,WINDOW_NORMAL); <span class="comment">//not resizable window;</span></span><br><span class="line">	Mat frameTotal;</span><br><span class="line">	<span class="comment">//Rect Total(0, 150, 640, 180);//全画幅</span></span><br><span class="line">	<span class="function">Rect <span class="title">Lrect</span><span class="params">(<span class="number">0</span>,<span class="number">0</span>, <span class="number">2560</span>/<span class="number">2</span>,<span class="number">720</span>)</span></span>;<span class="comment">//左ROI</span></span><br><span class="line">	<span class="function">Rect <span class="title">Rrect</span><span class="params">(<span class="number">2560</span> / <span class="number">2</span>, <span class="number">0</span>, <span class="number">2560</span>/<span class="number">2</span>, <span class="number">720</span>)</span></span>; <span class="comment">//右ROI</span></span><br><span class="line">	<span class="keyword">while</span> (<span class="number">1</span>)</span><br><span class="line">	&#123;</span><br><span class="line">		cap &gt;&gt; frameTotal;</span><br><span class="line">		imshow(<span class="string">&quot;video | q or esc to quit&quot;</span>, frameTotal);</span><br><span class="line">		<span class="keyword">char</span> key = (<span class="keyword">char</span>)waitKey(<span class="number">30</span>);</span><br><span class="line">		<span class="keyword">switch</span> (key)</span><br><span class="line">		&#123;</span><br><span class="line">		<span class="keyword">case</span><span class="number">&#x27;</span>q<span class="number">&#x27;</span>:</span><br><span class="line">		<span class="keyword">case</span><span class="number">&#x27;</span>Q<span class="number">&#x27;</span>:</span><br><span class="line">		<span class="keyword">case</span> <span class="number">27</span>:</span><br><span class="line">			<span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">		<span class="keyword">case</span> <span class="string">&#x27; &#x27;</span>:</span><br><span class="line">			sprintf_s(filename, <span class="string">&quot;Capture_%d.jpg&quot;</span>, i);</span><br><span class="line">			imwrite(filename, frameTotal);<span class="comment">//保存全画幅</span></span><br><span class="line">			sprintf_s(filename, <span class="string">&quot;L_%d.jpg&quot;</span>, i);</span><br><span class="line">			imwrite(filename, frameTotal(Lrect));<span class="comment">//保存左画幅</span></span><br><span class="line">			sprintf_s(filename, <span class="string">&quot;R_%d.jpg&quot;</span>, i);</span><br><span class="line">			imwrite(filename, frameTotal(Rrect));<span class="comment">//保存右画幅</span></span><br><span class="line">			<span class="built_in">cout</span> &lt;&lt; <span class="string">&quot;捕捉到第&quot;</span>&lt;&lt;i&lt;&lt;<span class="string">&quot;组图像&quot;</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">			i++;</span><br><span class="line">		<span class="keyword">default</span>:</span><br><span class="line">			<span class="keyword">break</span>;</span><br><span class="line">		&#125;</span><br><span class="line">		</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="相机标定代码">相机标定代码</h3>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;opencv2/opencv.hpp&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;opencv2/calib3d/calib3d.hpp&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;opencv2/highgui/highgui.hpp&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;opencv2/imgproc/imgproc.hpp&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="comment">//定义标定板内角点维数</span></span><br><span class="line"><span class="keyword">int</span> CHESSBOARD[<span class="number">2</span>] = &#123; <span class="number">6</span>,<span class="number">9</span> &#125;;<span class="comment">//纵向6个角点，横向9个角点</span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> cv;</span><br><span class="line"> </span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">	<span class="comment">//////// 标定数据集的导入 //////////</span></span><br><span class="line">	<span class="built_in">vector</span>&lt;String&gt; image_paths;<span class="comment">//数据集中图像的路径</span></span><br><span class="line">	<span class="built_in">string</span> path = <span class="string">&quot;.\\data_set40\\Right&quot;</span>;<span class="comment">//图像名称格式</span></span><br><span class="line">	glob(path,image_paths);<span class="comment">// 将所有符合格式的图像路径存储到image_paths中</span></span><br><span class="line"></span><br><span class="line">	<span class="comment">////// 世界坐标系三维坐标输入 //////</span></span><br><span class="line">	<span class="built_in">vector</span>&lt;Point3f&gt;objp; <span class="comment">// 存储关键点在真实世界中的三维坐标</span></span><br><span class="line">	<span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; CHESSBOARD[<span class="number">1</span>]; i++)</span><br><span class="line">	&#123;</span><br><span class="line">		<span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; CHESSBOARD[<span class="number">0</span>]; j++)</span><br><span class="line">			objp.push_back(Point3f(i, j, <span class="number">0</span>));<span class="comment">//逐行标记内角点坐标</span></span><br><span class="line">	&#125;</span><br><span class="line">	</span><br><span class="line"></span><br><span class="line">	Mat src,img;<span class="comment">//图像</span></span><br><span class="line">	<span class="built_in">vector</span>&lt;Point2f&gt; corners;</span><br><span class="line">	<span class="keyword">bool</span> found;</span><br><span class="line">	<span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;Point3f&gt;&gt; objPoints;<span class="comment">//为整个数据集创建其在真实世界的三维坐标集合。</span></span><br><span class="line">	<span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;Point2f&gt;&gt; imgPoints;<span class="comment">//图像上的关键点坐标位置</span></span><br><span class="line">	<span class="comment">///////// 遍历数据集 &amp;&amp; 确定关键点位置 ///////////</span></span><br><span class="line">	<span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; image_paths.size(); i++)</span><br><span class="line">	&#123;</span><br><span class="line">		src = imread(image_paths[i]);</span><br><span class="line">		cvtColor(src, img, COLOR_BGR2GRAY);</span><br><span class="line">		<span class="comment">//寻找关键点位置</span></span><br><span class="line">		found = findChessboardCorners(img, </span><br><span class="line">									Size(CHESSBOARD[<span class="number">0</span>], CHESSBOARD[<span class="number">1</span>]),corners, </span><br><span class="line">									CALIB_CB_ADAPTIVE_THRESH + CALIB_CB_NORMALIZE_IMAGE + CALIB_CB_FAST_CHECK);</span><br><span class="line">		<span class="keyword">if</span> (found)<span class="comment">//在图像上确定出内角点信息</span></span><br><span class="line">		&#123;</span><br><span class="line">			<span class="function">TermCriteria <span class="title">criteria</span><span class="params">(CV_TERMCRIT_EPS | CV_TERMCRIT_ITER, <span class="number">30</span>, <span class="number">0.001</span>)</span></span>;<span class="comment">//设置最大迭代次数与迭代终止条件</span></span><br><span class="line">			<span class="comment">//使用亚像素精准化关键点坐标位置</span></span><br><span class="line">			cornerSubPix(img, corners, cv::Size(<span class="number">11</span>, <span class="number">11</span>), cv::Size(<span class="number">-1</span>, <span class="number">-1</span>), criteria);</span><br><span class="line">			<span class="comment">//在图像上显示检测到的关键点</span></span><br><span class="line">			drawChessboardCorners(src, cv::Size(<span class="number">6</span>, <span class="number">9</span>), corners, found);</span><br><span class="line"></span><br><span class="line">			objPoints.push_back(objp);</span><br><span class="line">			imgPoints.push_back(corners);</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="comment">//namedWindow(&quot;Corner Detected&quot;, WINDOW_KEEPRATIO);</span></span><br><span class="line">		cv::imshow(<span class="string">&quot;Corner Detected&quot;</span>, src);<span class="comment">//展示图像</span></span><br><span class="line">		waitKey(<span class="number">0</span>);</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	</span><br><span class="line">	cv::destroyAllWindows();</span><br><span class="line">	<span class="comment">////////// 计算相机内外参数 ///////////</span></span><br><span class="line">	cv::Mat cameraMatrix, distCoeffs, R, T;</span><br><span class="line">	cv::calibrateCamera(objPoints, imgPoints, cv::Size(img.rows,img.cols), cameraMatrix, distCoeffs, R, T);</span><br><span class="line">	<span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt; <span class="string">&quot;cameraMatrix : &quot;</span> &lt;&lt; cameraMatrix &lt;&lt; <span class="built_in">std</span>::<span class="built_in">endl</span>;</span><br><span class="line">	<span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt; <span class="string">&quot;distCoeffs : &quot;</span> &lt;&lt; distCoeffs &lt;&lt; <span class="built_in">std</span>::<span class="built_in">endl</span>;</span><br><span class="line">	<span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt; <span class="string">&quot;Rotation vector : &quot;</span> &lt;&lt; R &lt;&lt; <span class="built_in">std</span>::<span class="built_in">endl</span>;</span><br><span class="line">	<span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt; <span class="string">&quot;Translation vector : &quot;</span> &lt;&lt; T &lt;&lt; <span class="built_in">std</span>::<span class="built_in">endl</span>;</span><br><span class="line">	<span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="畸变矫正代码">畸变矫正代码</h3>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;opencv2/opencv.hpp&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;opencv2/highgui/highgui.hpp&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> cv;</span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">	cv::Mat image;</span><br><span class="line">	image = cv::imread(<span class="string">&quot;1.jpg&quot;</span>);</span><br><span class="line">	cv::Mat cameraMatrix, distCoeffs;</span><br><span class="line">	cv::Mat dst, map1, map2, new_camera_matrix;</span><br><span class="line">	<span class="function">cv::Size <span class="title">imageSize</span><span class="params">(cv::Size(image.cols, image.rows))</span></span>;</span><br><span class="line">	<span class="comment">//对左摄像头采集到的图像进行矫正</span></span><br><span class="line">    <span class="comment">//镜头内参输入</span></span><br><span class="line">	cameraMatrix = (Mat_&lt;<span class="keyword">float</span>&gt;(<span class="number">3</span>,<span class="number">3</span>)&lt;&lt; <span class="number">1363.068832071628</span>, <span class="number">0</span>, <span class="number">597.5310820482522</span>,<span class="number">0</span>, <span class="number">1364.502172300807</span>, <span class="number">380.6142772218984</span>,<span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>);<span class="comment">//相机内参矩阵</span></span><br><span class="line">	distCoeffs = (Mat_&lt;<span class="keyword">float</span>&gt;(<span class="number">1</span>, <span class="number">5</span>) &lt;&lt; <span class="number">-0.4401953292696111</span>, <span class="number">0.1678238673295687</span>, <span class="number">4.136661811836659e-05</span>, <span class="number">0.001406248426772503</span>, <span class="number">0.1224192370990156</span>);<span class="comment">//相机畸变向量</span></span><br><span class="line"></span><br><span class="line">	<span class="comment">//计算畸变映射矩阵</span></span><br><span class="line">	cv::initUndistortRectifyMap(cameraMatrix, distCoeffs, cv::Mat(), cv::getOptimalNewCameraMatrix(cameraMatrix, distCoeffs, imageSize, <span class="number">0</span>, imageSize, <span class="number">0</span>), imageSize, CV_16SC2, map1, map2);</span><br><span class="line">	<span class="comment">//畸变矫正</span></span><br><span class="line">	cv::remap(image, dst, map1, map2, cv::INTER_LINEAR);</span><br><span class="line">	imshow(<span class="string">&quot;Distorted img&quot;</span>, dst);</span><br><span class="line">	cvWaitKey(<span class="number">0</span>);</span><br><span class="line"></span><br><span class="line">	<span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="四参考资料">四、参考资料</h2>
<p>主要参考以下博文：</p>
<ul>
<li><a href="https://www.learnopencv.com/camera-calibration-using-opencv/">Camera Calibration using OpenCV</a></li>
<li><a href="https://www.learnopencv.com/geometry-of-image-formation/">Geometry of Image Formation</a></li>
<li><a href="https://blog.csdn.net/datase/article/details/77587357">张正友法标定流程</a></li>
<li><a href="https://blog.csdn.net/u013289254/article/details/99200881">vs2015 + opencv3 双目摄像头标定（C++实现）</a></li>
<li><a href="https://jingyan.baidu.com/article/63f2362826ea1c0208ab3dec.html">相机标定之四个坐标系及其关系</a></li>
<li><a href="https://www.pomeas.cn/newsview/529.html">什么是亚像素？</a></li>
<li><a href="https://www.cnblogs.com/riddick/p/6711263.html">OpenCV畸变校正原理以及损失有效像素原理分析</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/66863619">Opencv中的两种去畸变函数</a></li>
<li><a href="https://blog.csdn.net/yghjkliikk/article/details/110070315">cv2.getOptimalNewCameraMatrix中的alpha和roi参数</a></li>
</ul>
]]></content>
      <categories>
        <category>计算机视觉</category>
      </categories>
      <tags>
        <tag>相机标定</tag>
        <tag>双目摄像头</tag>
        <tag>图像测量</tag>
      </tags>
  </entry>
  <entry>
    <title>使用HOG+MOSSE实现行人检测与跟踪</title>
    <url>/2021/01/03/%E8%A1%8C%E4%BA%BA%E6%A3%80%E6%B5%8Bdemo%E8%AF%B4%E6%98%8E%E6%96%87%E6%A1%A3/</url>
    <content><![CDATA[<h1 id="行人检测跟踪demo说明文档">行人检测/跟踪demo说明文档</h1>
<p>本行人检测demon使用HOG描述子+SVM分类器进行实现，采用跟踪速度较快的MOSSE跟踪器进行跟踪，每15帧进行一次行人检测进而对检测到的行人数量进行一次刷新。行人检测/跟踪效果如下</p>
<figure>
<img src="https://blogpicbed.oss-cn-beijing.aliyuncs.com/img/scale1_05_22_Mean.gif" alt="scale1_05_22_Mean" /><figcaption aria-hidden="true">scale1_05_22_Mean</figcaption>
</figure>
<h2 id="一理论基础">一、理论基础</h2>
<p>行人检测、跟踪涉及目标检测与目标跟踪两大部分。对于目标检测部分，其大体流程图如下图所示。首先对于一张输入的图片，我们首先要使用<strong>特征描述子</strong>对它提取特征，特征描述子可以将目标区域输出为向量形式，我们称该向量为<strong>特征向量</strong>，常用的特征描述子有:HOG，SIFT，HAAR，SARF等。接下来我们要将特征描述子提取出的特征向量输入到训练好的分类器中，常见的分类器有SVM、Adaboost、ANN等。分类器输出的内容为分类标签，对于目标检测问题，分类器会输出判断结果(该区域是/否存在目标)，对于多分类问题分类器会输出不同的类别标签。</p>
<figure>
<img src="https://blogpicbed.oss-cn-beijing.aliyuncs.com/img/image-classification-pipeline.jpg" alt="image-classification-pipeline" /><figcaption aria-hidden="true">image-classification-pipeline</figcaption>
</figure>
<h3 id="hog特征描述子">1.1 HOG特征描述子</h3>
<h4 id="什么是特征描述子">1.1.1 什么是特征描述子？</h4>
<p><strong>什么是图像的特征？</strong>特征是描述目标的一种方法，或者是目标的一种特点。生活中我们常通过身材、性别、年龄、长相、嗓音等特征描述一个人，同样对于图像，我们可以通过颜色(颜色直方图)、形状(SIFT、HOG、Haar)、纹理、边缘(canny算子、sobel算子)等特征进行描述。</p>
<p><strong>什么是特征描述子？</strong>特征描述子是提取特定特征的手段，不同的特征描述子只能提取特定类型的特征。那么我们为什么要提取出特定特征呢？因为对于很多目标检测和分类问题，并非所有特征都对我们是有用的，比如说，在一个检测大衣上纽扣数量的任务中，因为纽扣的形状是圆形的，所以我们可以直接通过纽扣的轮廓来检测到纽扣，这时候纽扣的边缘或者说轮廓信息对我们是有用的，而纽扣的颜色信息对我们的就是无用的或者说冗余的。所以说，在这个任务中我们就可以选取一种只提取纽扣边缘信息的描述子来参与运算，而我们后面要提到的hog描述子就是一个典型的基于轮廓信息的描述子。另一方面，从输入输出角度来看，特征描述子可以将我们输入的图片样本转化为特征向量。</p>
<h4 id="hog特征描述子的原理">1.1.2 HOG特征描述子的原理</h4>
<p>HOG特征描述子是一类典型的提取目标轮廓信息的描述子，与所有特征描述子一样，HOG描述子的输入是一张照片，输出是一个特征向量。HOG特征描述子的内部原理可以参考：<a href="https://blog.csdn.net/qq_35000721/article/details/109441618">HOG原理学习笔记</a></p>
<h3 id="svm分类器">1.2 SVM分类器</h3>
<p>支持向量机的本质是在特征向量所在的特征空间中，寻找一个最恰当的超平面来划分两类/多类目标。对于其数学原理我们不过分深究，我们只需要了解到，对于一个训练好的分类器，当我们对它输入目标的特征向量，其输出应该是目标的分类标签即可。</p>
<h3 id="目标跟踪算法">1.3 目标跟踪算法</h3>
<p>目标跟踪是一种在视频中确定目标位置的方法。相比于逐帧对整张画面进行目标检测从而定位目标的方法，目标跟踪类算法会依靠目标之前的运行轨迹来对目标未来的轨迹进行预判，进而在小范围内对目标进行搜索，从而提高了运算速度。同时目标跟踪算法会对每个目标建立身份信息，而目标检测算法并不会区分目标之间的不同。</p>
<h2 id="二代码实现">二、代码实现</h2>
<p>本项目的例程文件结构如下：</p>
<figure>
<img src="https://blogpicbed.oss-cn-beijing.aliyuncs.com/img/image-20210103162822272.png" alt="image-20210103162822272" /><figcaption aria-hidden="true">image-20210103162822272</figcaption>
</figure>
<ul>
<li><strong>hogDetext.h</strong>：包含了hog特征描述子类的声明</li>
<li><strong>function.cpp</strong>：包含了hog特征描述子类的实现，其中的<code>hog.detectMultiScale()</code>部分是本例程中参数调节的重点。</li>
<li><strong>MOT_count.cpp：</strong>主程序</li>
</ul>
<h3 id="目标检测器的封装">2.1 目标检测器的封装</h3>
<p>我们首先读取视频的第一帧，并对该帧中的行人进行检测从而判断行人的初始位置。为了方便起见，我们在<code>hogDetext.h</code>中创建了hog行人检测器类<code>HogDetector</code>，对HOG描述子与SVM分类器的参数设置进行了封装，该类的参数调节对目标检测的效果以及运算速度有着显著的影响。该类的具体声明如下：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">HogDetector</span> </span></span><br><span class="line"><span class="class">&#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">	<span class="built_in">vector</span>&lt;<span class="keyword">double</span>&gt; weights;</span><br><span class="line">	HogDetector(); <span class="comment">// 创建HOG行人检测器</span></span><br><span class="line">	HogDetector(Mat _src); <span class="comment">// 对某图提取HOG特征</span></span><br><span class="line">	~HogDetector();</span><br><span class="line">	<span class="function"><span class="built_in">vector</span>&lt;Rect&gt; <span class="title">hogSvm</span><span class="params">()</span></span>; <span class="comment">// 成员函数，对当前帧进行行人检测</span></span><br><span class="line">	</span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">	Mat src;<span class="comment">//存储当前帧</span></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<p>观察类的声明我们可以得知，在需要对某张图片进行检测时，我们只需要使用<code>HogDetector(Mat _src)</code>输入目标图像，再利用<code>vector&lt;Rect&gt; hogSvm()</code>对目标进行检测即可。成员函数<code>hogSvm()</code>很重要，该成员函数需要完成三部分工作：设定使用到的SVM分类器、对当前帧进行多尺度的目标检测、人工剔除相互嵌套的目标区域。</p>
<h4 id="选择分类器">2.1.1 选择分类器</h4>
<p>由理论部分可知，HOG特征描述子提取出的特征向量需要输入一个已经训练好的SVM分类器中，对于行人检测场景，opencv官方提供了针对行人检测训练的SVM分类器，该分类器是基于HOG特征描述子提出者使用的数据集进行训练的，我们只需要人为的设定使用该分类器即可。其实现代码如下：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line">HOGDescriptor hog;</span><br><span class="line">hog.setSVMDetector(HOGDescriptor::getDefaultPeopleDetector());<span class="comment">//使用官方训练的SVM分类器</span></span><br></pre></td></tr></table></figure>
<h4 id="多尺度的行人检测">2.1.2 多尺度的行人检测</h4>
<p>在选定了SVM分类器后我们需要对一张图片在多尺度上进行目标检测，为什么要在多尺度上进行目标检测呢？最传统的目标检测手段是使用一个滑动的窗口，来逐行对图像区域提取特征从而输入到分类器中。而在一张画面中目标由于远近关系，其大小会有不同(放缩)，多尺度的目标检测可以通过设置合理的参数来消除目标放缩对检测所带来的影响，我们使用到的函数是<code>detectMultiScale()</code>，其声明如下：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">void</span> cv::HOGDescriptor::detectMultiScale	(	InputArray 	img,</span><br><span class="line">											<span class="built_in">std</span>::<span class="built_in">vector</span>&lt; Rect &gt; &amp; 	foundLocations,</span><br><span class="line">											<span class="keyword">double</span> 	hitThreshold = <span class="number">0</span>,</span><br><span class="line">											Size 	winStride = Size(),</span><br><span class="line">											Size 	padding = Size(),</span><br><span class="line">											<span class="keyword">double</span> 	scale = <span class="number">1.05</span>,</span><br><span class="line">											<span class="keyword">double</span> 	finalThreshold = <span class="number">2.0</span>,</span><br><span class="line">											<span class="keyword">bool</span> 	useMeanshiftGrouping = <span class="literal">false</span> </span><br><span class="line">											)	</span><br></pre></td></tr></table></figure>
<ul>
<li><strong>img</strong>：图像输入</li>
<li><strong>foundLocations</strong> ：检测结果输出。存储了位置矩形的向量，位置矩形中包含了检测到目标的位置信息。其类型为std::vector&lt; Rect &gt;</li>
<li><strong>hitThreshold</strong>：Threshold for the distance between features and SVM classifying plane. Usually it is 0 and should be specified in the detector coefficients (as the last free coefficient). But if the free coefficient is omitted (which is allowed), you can specify it manually here. 图像特征向量到SVM超平面的距离，一般取0</li>
<li><strong>winStride</strong>：It must be a multiple of block stride. HOG检测窗口移动时的步长(水平及竖直)。</li>
<li><strong>padding</strong>：在某些情况下在图像周围增加一些像素来提升检测精确度，默认不添加</li>
<li><strong>scale</strong>：Coefficient of the detection window increase. 多尺度目标检测的控制参数，取值范围一般在1.01-1.5之间。通常情况下，取值越小，检测越细致，但计算量越大，出现目标嵌套的情况也越多</li>
<li><strong>finalThreshold</strong>： 默认取2</li>
<li><strong>useMeanshiftGrouping</strong>：选择是否使用Meanshift法消除多个检测窗口嵌套的情况，本示例中选择开启</li>
</ul>
<p><strong>在调试程序时，<code>winStride</code>与<code>scale</code>是两个极为重要的参数，对二者进行调节可以显著的提升程序的检测效果。</strong></p>
<h4 id="消除检测框相互嵌套">2.1.3 消除检测框相互嵌套</h4>
<p>在实际操作中，我们可能在多个尺度上都检测到了同一个目标，这是标记目标位置的矩形会出现嵌套情况，我们希望能检测出相互嵌套的的矩形，剔除被嵌套的矩形，只保留外部矩形，从而消除对同一目标的重复检测情况。该部分代码实现如下：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; found.size(); i++)</span><br><span class="line">	&#123;</span><br><span class="line">		Rect r = found[i];</span><br><span class="line">		<span class="keyword">int</span> j = <span class="number">0</span>;</span><br><span class="line">		<span class="keyword">for</span> (; j &lt; found.size(); j++)</span><br><span class="line">		&#123;</span><br><span class="line">			<span class="keyword">if</span> (i != j &amp;&amp; (r &amp; found[j]) == r)<span class="keyword">break</span>;<span class="comment">// 若r被嵌套于其他矩形中则跳出循环</span></span><br><span class="line">		&#125;</span><br><span class="line">		<span class="keyword">if</span> (j == found.size())<span class="comment">// 全部检测完</span></span><br><span class="line">		&#123;</span><br><span class="line">			foundfilter.push_back(r);</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br></pre></td></tr></table></figure>
<h3 id="主程序流程">2.2 主程序流程</h3>
<p>在人为的对HOG目标检测器进行封装之后，我们只需要按照下图所示的程序流程图反复调用目标检测器与目标跟踪器即可。由于随着时间流逝，场景中部分目标会离开画面，部分新目标会进入画面，而目标跟踪算法并不能对新目标进行识别，所以我们需要间隔的进行目标检测，从而更新我们检测到的目标。在本项目中我们选择“每15帧进行目标检测”作为“是否重新检测目标”的标准。</p>
<figure>
<img src="https://blogpicbed.oss-cn-beijing.aliyuncs.com/img/行人检测与跟踪流程图.svg" alt="行人检测与跟踪流程图" /><figcaption aria-hidden="true">行人检测与跟踪流程图</figcaption>
</figure>
<h4 id="目标检测">2.2.1 目标检测</h4>
<p>对于满足需要进行目标检测的帧，我们需要调用我们封装好的HOG检测器。经过我们的封装后，调用HOG特征描述子的方式很简单，具体如下</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function">HogDetector <span class="title">hog</span><span class="params">(frame)</span></span>; <span class="comment">//输入当前帧frame</span></span><br><span class="line">targetBoxs = hog.hogSvm();<span class="comment">//目标检测，并将检测结果输出到targetBoxs中</span></span><br></pre></td></tr></table></figure>
<p>在目标检测完成后，我们需要人为的将检测到目标的区域显示在画面上，该部分使用到了矩形绘制函数<code>rectangle()</code>以及字符显示函数<code>putText()</code>。同时为了后续的优化升级，我们将每个检测到的目标区域的置信度显示在了画面上。</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; targetBoxs.size(); i++)</span><br><span class="line">	&#123;</span><br><span class="line">		rectangle(frame,targetBoxs[i],Scalar(<span class="number">0</span>, <span class="number">255</span>, <span class="number">0</span>),<span class="number">2</span>);<span class="comment">//绘制矩形</span></span><br><span class="line">		<span class="keyword">char</span> text[<span class="number">21</span>];</span><br><span class="line">		sprintf_s(text, <span class="string">&quot;%.2lf&quot;</span>, hog.weights[i]);<span class="comment">//表明每个目标的置信度</span></span><br><span class="line">		putText(frame, text, targetBoxs[i].tl(), FONT_HERSHEY_SIMPLEX, <span class="number">0.5</span>, Scalar(<span class="number">255</span>, <span class="number">0</span>, <span class="number">0</span>), <span class="number">1.5</span>);<span class="comment">//表明每个目标的置信度</span></span><br><span class="line">	&#125;</span><br></pre></td></tr></table></figure>
<h4 id="多目标跟踪">2.2.2 多目标跟踪</h4>
<p>对于不需要重新进行目标检测的画面，我们调用跟踪器对目标进行跟踪。opencv中实现了八种类型的跟踪器：BOOSTING, MIL, KCF, TLD, MEDIANFLOW, GOTURN, MOSSE, CSRT。关于它们的性能对比，请参考<a href="https://www.learnopencv.com/object-tracking-using-opencv-cpp-python/">Object Tracking using OpenCV (C++/Python)</a>。目标跟踪器的输入是目标在上一帧的位置，其输出是目标在下一帧的位置。</p>
<p>由于画面中存在多个目标，我们需要调用opencv中的多目标跟踪器类，并通过循环人为规定每个跟踪器的类型为MOSSE，该部分实现如下：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="built_in">vector</span>&lt;Rect&gt; targetBoxs;<span class="comment">// 存储了行人位置/目标检测器的输出</span></span><br><span class="line">Mat frame;<span class="comment">//当前帧</span></span><br><span class="line">Ptr&lt;MultiTracker&gt; multiTracker = cv::MultiTracker::create();</span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; targetBoxs.size(); i++)</span><br><span class="line">&#123;</span><br><span class="line">	multiTracker-&gt;add(TrackerMOSSE::create(), frame, Rect2d(targetBoxs[i]));</span><br><span class="line">&#125;</span><br><span class="line">multiTracker-&gt;update(frame);<span class="comment">//在当前帧中更新目标位置</span></span><br></pre></td></tr></table></figure>
<p>最后我们需要在画面中绘制出目标的位置，此部分代码与目标检测部分相同，故不再赘述。</p>
<h4 id="统计目标信息">2.2.3 统计目标信息</h4>
<p>程序的最后我们需要将我们检测到的目标数量进行统计输出，代码如下。</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line">putText(frame, <span class="string">&quot;Total people:&quot;</span> + to_string(targetBoxs.size()), Point(<span class="number">600</span>, <span class="number">40</span>), FONT_HERSHEY_SIMPLEX, <span class="number">1</span>, Scalar(<span class="number">0</span>, <span class="number">0</span>, <span class="number">255</span>), <span class="number">2.5</span>);</span><br></pre></td></tr></table></figure>
<h2 id="三程序源码">三、程序源码</h2>
<p><strong>hogDetext.h</strong></p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">ifndef</span> HOGDETECT_H</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;string&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;string&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;opencv2/core/core.hpp&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;opencv2/highgui/highgui.hpp&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;opencv2/imgproc/imgproc.hpp&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;opencv2/objdetect/objdetect.hpp&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;opencv2/ml/ml.hpp&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;opencv2/opencv.hpp&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;ctime&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> cv;</span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> cv::ml;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">HogDetector</span> </span></span><br><span class="line"><span class="class">&#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">	<span class="built_in">vector</span>&lt;<span class="keyword">double</span>&gt; weights;</span><br><span class="line">	HogDetector(); <span class="comment">// 创建HOG行人检测器</span></span><br><span class="line">	HogDetector(Mat _src); <span class="comment">// 对某图提取HOG特征</span></span><br><span class="line">	~HogDetector();</span><br><span class="line">	<span class="function"><span class="built_in">vector</span>&lt;Rect&gt; <span class="title">hogSvm</span><span class="params">()</span></span>; <span class="comment">// 成员函数，对当前帧进行行人检测</span></span><br><span class="line">	</span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">	Mat src;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p><strong>function.cpp</strong></p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&quot;hogDetect.h&quot;</span></span></span><br><span class="line"></span><br><span class="line">HogDetector::HogDetector() </span><br><span class="line">&#123;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">HogDetector::HogDetector(Mat _src)</span><br><span class="line">&#123;</span><br><span class="line">	src = _src;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">HogDetector::~HogDetector()</span><br><span class="line">&#123;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="built_in">vector</span>&lt;Rect&gt; <span class="title">HogDetector::hogSvm</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"></span><br><span class="line">	<span class="built_in">vector</span>&lt;Rect&gt; found, foundfilter;<span class="comment">//存储外接矩形的容器</span></span><br><span class="line">	<span class="keyword">clock_t</span> start, total; <span class="comment">//设置计时变量</span></span><br><span class="line">	start = clock();<span class="comment">//开始计时</span></span><br><span class="line">	<span class="comment">//-------------------HOG+SVM参数设置(行人检测器的初始化)-----------------------</span></span><br><span class="line">	<span class="comment">//创建HOG特征提取器</span></span><br><span class="line">	HOGDescriptor hog;</span><br><span class="line">	<span class="comment">//使用官方训练的SVM分类器</span></span><br><span class="line">	hog.setSVMDetector(HOGDescriptor::getDefaultPeopleDetector());</span><br><span class="line">	<span class="comment">//搜索方式(滑窗)设置</span></span><br><span class="line">	hog.detectMultiScale(src, <span class="comment">// 输入需要检测的帧</span></span><br><span class="line">						found, <span class="comment">// 输出检测到目标的多个区域信息</span></span><br><span class="line">						weights,<span class="comment">//输出对每个检测到的目标的置信度</span></span><br><span class="line">						<span class="number">0</span>, <span class="comment">// 图像特征向量到SVM超平面的距离，默认取0</span></span><br><span class="line">						Size(<span class="number">2</span>, <span class="number">2</span>), <span class="comment">//winStride **非常重要** HoG检测窗口移动时的步长(水平及竖直)。</span></span><br><span class="line">						Size(<span class="number">0</span>, <span class="number">0</span>),<span class="comment">//在原图外添加一些像素以增加精确度，我们默认不添加</span></span><br><span class="line">						<span class="number">1.05</span>, <span class="comment">//scale **非常重要** 控制图像金字塔的层数 取值范围1.01-1.5 ——&gt;图像多尺度表示的控制</span></span><br><span class="line">						<span class="number">2</span>,<span class="literal">true</span>);<span class="comment">//默认);</span></span><br><span class="line">	<span class="comment">//winStride和scale都是比较重要的参数，需要合理的设置。一个合适参数能够大大提升检测精确度，同时也不会使检测时间太长。</span></span><br><span class="line">	<span class="comment">//hog.groupRectangles(found, weights,10,2);</span></span><br><span class="line">	<span class="comment">//获取检测时间(ms)</span></span><br><span class="line">	total = (<span class="keyword">double</span>)(<span class="number">1000</span> * (clock() - start) / CLOCKS_PER_SEC);</span><br><span class="line">	<span class="built_in">cout</span> &lt;&lt; <span class="string">&quot;检测用时: &quot;</span> &lt;&lt; total &lt;&lt; <span class="string">&quot;ms!&quot;</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">	<span class="comment">//-----------------------剔除嵌套--------------------------</span></span><br><span class="line">	<span class="comment">// 使用Rect类交运算剔除掉被嵌套的Rect类</span></span><br><span class="line">	<span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; found.size(); i++)</span><br><span class="line">	&#123;</span><br><span class="line">		Rect r = found[i];</span><br><span class="line">		<span class="keyword">int</span> j = <span class="number">0</span>;</span><br><span class="line">		<span class="keyword">for</span> (; j &lt; found.size(); j++)</span><br><span class="line">		&#123;</span><br><span class="line">			<span class="keyword">if</span> (i != j &amp;&amp; (r &amp; found[j]) == r)<span class="keyword">break</span>;<span class="comment">// 若r被嵌套于其他矩形中则跳出循环</span></span><br><span class="line">		&#125;</span><br><span class="line">		<span class="keyword">if</span> (j == found.size())<span class="comment">// 全部检测完</span></span><br><span class="line">		&#123;</span><br><span class="line">			foundfilter.push_back(r);</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	</span><br><span class="line">	<span class="keyword">return</span> foundfilter;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p><strong>MOT_count.cpp</strong>：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">//使用HOG+SVM进行行人检测</span></span><br><span class="line"><span class="comment">//使用官方SVM分类器</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;opencv2/opencv.hpp&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;opencv2/highgui/highgui.hpp&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;opencv2/tracking.hpp&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&quot;hogDetect.h&quot;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> cv;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">	Mat frame;<span class="comment">//创建一个Mat类的帧</span></span><br><span class="line">	<span class="function">VideoCapture <span class="title">cap</span><span class="params">(<span class="string">&quot;1.mp4&quot;</span>)</span></span>;<span class="comment">//载入视频</span></span><br><span class="line">	<span class="keyword">bool</span> ok  = cap.read(frame);<span class="comment">//读取视频的第一帧</span></span><br><span class="line">	<span class="function">VideoWriter <span class="title">videowriter</span><span class="params">(<span class="string">&quot;行人检测效果.avi&quot;</span>, VideoWriter::fourcc(<span class="string">&#x27;M&#x27;</span>, <span class="string">&#x27;J&#x27;</span>, <span class="string">&#x27;P&#x27;</span>, <span class="string">&#x27;G&#x27;</span>), <span class="number">30</span>, Size(frame.cols, frame.rows), <span class="literal">true</span>)</span></span>;<span class="comment">//视频存储器初始化</span></span><br><span class="line">	<span class="keyword">if</span> (!cap.isOpened())</span><br><span class="line">	&#123;</span><br><span class="line">		<span class="built_in">cout</span> &lt;&lt; <span class="string">&quot;未正确读取视频!&quot;</span>&lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="comment">///////////////// 检测器初始化 ///////////////////</span></span><br><span class="line">	<span class="comment">//对第一帧进行行人检测</span></span><br><span class="line">	<span class="built_in">vector</span>&lt;Rect&gt; targetBoxs;<span class="comment">// 存储行人位置</span></span><br><span class="line">	<span class="function">HogDetector <span class="title">hog</span><span class="params">(frame)</span></span>; <span class="comment">//对frame帧创建hog特征描述子</span></span><br><span class="line">	targetBoxs = hog.hogSvm();<span class="comment">// 进行行人检测</span></span><br><span class="line">	<span class="comment">//for (int i = 0; i &lt; targetBoxs.size(); i++)</span></span><br><span class="line">	<span class="comment">//&#123;</span></span><br><span class="line">		<span class="comment">//rectangle(frame, targetBoxs[i], Scalar(0, 0, 255), 3);</span></span><br><span class="line">	<span class="comment">//&#125;</span></span><br><span class="line">	</span><br><span class="line">	<span class="comment">///////////// 逐帧跟踪 &amp; 15帧检测 ////////////////////</span></span><br><span class="line">	<span class="keyword">while</span> (cap.isOpened())</span><br><span class="line">	&#123;</span><br><span class="line">		cap &gt;&gt; frame;<span class="comment">// 当前帧</span></span><br><span class="line">		<span class="keyword">if</span> (frame.empty()) <span class="keyword">break</span>;</span><br><span class="line">		<span class="comment">///////////////////////// 跟踪&amp;检测判断 ///////////////////////////////</span></span><br><span class="line">		<span class="keyword">int</span> frameNum = cap.get(CV_CAP_PROP_POS_FRAMES);<span class="comment">// 获取当前帧序号</span></span><br><span class="line">		<span class="keyword">if</span> (frameNum % <span class="number">15</span>== <span class="number">0</span>)<span class="comment">// 每15帧进行一次目标检测</span></span><br><span class="line">		&#123;</span><br><span class="line">			targetBoxs = hog.hogSvm();<span class="comment">// 获取行人位置 更新跟踪区域</span></span><br><span class="line">			<span class="comment">//画图,绘制出新检测到的目标位置</span></span><br><span class="line">			<span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; targetBoxs.size(); i++)</span><br><span class="line">			&#123;</span><br><span class="line">				rectangle(frame,targetBoxs[i],Scalar(<span class="number">0</span>, <span class="number">255</span>, <span class="number">0</span>),<span class="number">2</span>);<span class="comment">//绘制矩形</span></span><br><span class="line">				<span class="keyword">char</span> text[<span class="number">21</span>];</span><br><span class="line">				sprintf_s(text, <span class="string">&quot;%.2lf&quot;</span>, hog.weights[i]);<span class="comment">//表明每个目标的置信度</span></span><br><span class="line">				<span class="function"><span class="built_in">string</span> <span class="title">Weight</span><span class="params">(text)</span></span>;</span><br><span class="line">				putText(frame, Weight, targetBoxs[i].tl(), FONT_HERSHEY_SIMPLEX, <span class="number">0.5</span>, Scalar(<span class="number">255</span>, <span class="number">0</span>, <span class="number">0</span>), <span class="number">1.5</span>);<span class="comment">//表明每个目标的置信度</span></span><br><span class="line">			&#125;</span><br><span class="line">		&#125;	</span><br><span class="line">		<span class="keyword">else</span> <span class="comment">//其余帧进行目标跟踪</span></span><br><span class="line">		&#123;	<span class="comment">//////////////// 多目标跟踪器初始化 //////////////////</span></span><br><span class="line">			Ptr&lt;MultiTracker&gt; multiTracker = cv::MultiTracker::create();</span><br><span class="line">			<span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; targetBoxs.size(); i++)<span class="comment">// 为每个目标创建跟踪器</span></span><br><span class="line">			&#123;</span><br><span class="line">				multiTracker-&gt;add(TrackerMOSSE::create(), frame, Rect2d(targetBoxs[i]));<span class="comment">// 在第一帧上创建多目标跟踪器</span></span><br><span class="line">			&#125;</span><br><span class="line">			multiTracker-&gt;update(frame);<span class="comment">//进行目标跟踪</span></span><br><span class="line">			<span class="keyword">for</span> (<span class="keyword">unsigned</span> i = <span class="number">0</span>; i &lt; multiTracker-&gt;getObjects().size(); i++) <span class="comment">// 对跟踪目标进行绘制</span></span><br><span class="line">			&#123;</span><br><span class="line">				rectangle(frame, multiTracker-&gt;getObjects()[i], Scalar(<span class="number">0</span>, <span class="number">255</span> , <span class="number">0</span>),<span class="number">2</span>, <span class="number">1</span>); <span class="comment">// 标记出每个跟踪区域</span></span><br><span class="line">				<span class="keyword">char</span> text[<span class="number">21</span>];</span><br><span class="line">				sprintf_s(text, <span class="string">&quot;%.2lf&quot;</span>, hog.weights[i]);</span><br><span class="line">				<span class="function"><span class="built_in">string</span> <span class="title">Weight</span><span class="params">(text)</span></span>;</span><br><span class="line">				putText(frame, Weight, targetBoxs[i].tl(), FONT_HERSHEY_SIMPLEX, <span class="number">0.5</span>, Scalar(<span class="number">255</span>, <span class="number">0</span>, <span class="number">0</span>), <span class="number">1.5</span>);</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">		putText(frame, <span class="string">&quot;Total people:&quot;</span> + to_string(targetBoxs.size()), Point(<span class="number">600</span>, <span class="number">40</span>), FONT_HERSHEY_SIMPLEX, <span class="number">1</span>, Scalar(<span class="number">0</span>, <span class="number">0</span>, <span class="number">255</span>), <span class="number">2.5</span>);<span class="comment">//统计检测到的人数</span></span><br><span class="line">		putText(frame, <span class="string">&quot;Frame:&quot;</span> + to_string(cap.get(CV_CAP_PROP_POS_FRAMES)), Point(<span class="number">600</span>, <span class="number">80</span>), FONT_HERSHEY_SIMPLEX, <span class="number">1</span>, Scalar(<span class="number">0</span>, <span class="number">0</span>, <span class="number">255</span>), <span class="number">2.5</span>);<span class="comment">//显示当前帧</span></span><br><span class="line">		videowriter.write(frame);<span class="comment">//存储视频</span></span><br><span class="line">		namedWindow(<span class="string">&quot;Output Image&quot;</span>,WINDOW_AUTOSIZE);</span><br><span class="line">		imshow(<span class="string">&quot;Output Image&quot;</span>, frame);</span><br><span class="line">		<span class="keyword">if</span> (waitKey(<span class="number">1</span>) == <span class="number">27</span>)</span><br><span class="line">		&#123;</span><br><span class="line">			<span class="keyword">break</span>;</span><br><span class="line">		&#125;</span><br><span class="line">		</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>计算机视觉</category>
      </categories>
      <tags>
        <tag>HOG特征</tag>
        <tag>目标检测</tag>
        <tag>目标跟踪</tag>
      </tags>
  </entry>
  <entry>
    <title>摄影学基础(持续更新)</title>
    <url>/2021/01/16/%E6%91%84%E5%BD%B1%E5%AD%A6%E5%9F%BA%E7%A1%80/</url>
    <content><![CDATA[<h1 id="section"></h1>
<h2 id="像素">1.1 像素</h2>
<p>像素在图像的采集和图像的定义两个层面上有不同的定义。</p>
<ul>
<li>从图像采集层面上，像素代表相机感光阵列上的感光元(像元)器件，经常看到“单个像素尺寸”即是指单个感光元件的尺寸。一般来说，单个像素(感光元)越小，画面的细节越丰富，但受到噪声的影响越大；单个感光元越大，画面的信噪比越高，受到噪声的影响更小，同时由于单个感光元面积更大，在同样场景下可以采集到的光线更多，感光量增加，成像效果更明艳。</li>
</ul>
<p><img src="https://blogpicbed.oss-cn-beijing.aliyuncs.com/img/28555125231450371.JPEG" alt="img" style="zoom: 67%;" /></p>
<figure>
<img src="https://blogpicbed.oss-cn-beijing.aliyuncs.com/img/37413236672027783.JPEG" alt="img" /><figcaption aria-hidden="true">img</figcaption>
</figure>
<ul>
<li>从图像显示的层面上，像素代表组成图片的基本单元。图像是由许多小像素点在水平和垂直方向组成的。对于同一物体，更高的像素会带来更锐利的画面。</li>
</ul>
<figure>
<img src="https://blogpicbed.oss-cn-beijing.aliyuncs.com/img/v2-dc209163190f35c778f9bc664504297e_720w.jpg" alt="img" /><figcaption aria-hidden="true">img</figcaption>
</figure>
<h2 id="分辨率与分辨力">1.2 分辨率与分辨力</h2>
<p>从本质上讲，分辨率与分辨力都表示成像系统分辨出两个不通物体的极限能力，二者成倒数关系。</p>
<p>对于光学成像系统来说，以人眼成像系统为例，由于不存在采样离散化的过程，<strong>分辨率</strong>代表人眼能分辨出的最细黑白条纹数量(単位为线对/mm)，对于一副尺寸固定的图像，当它显示的黑白条纹数量超过人眼分辨率，人眼将会将该图像识别为灰色图像而非条纹图像。而人眼的<strong>分辨力</strong>则刚好是分辨率的倒数，代表人眼刚好能分辨的最细两条线之间的最小间隔,其单位为米(m) 制,即mm、μm或nm。</p>
<p>对于数字设备，其分辨力等于数字设备的单个像素尺寸。其分辨率在图像和显示层面上同样有两个不同的定义：图像分辨率和显示分辨率。</p>
<ul>
<li>图像分辨率，是单位英寸中所包含的像素点数，其单位为PPI(Pixels Per Inch)。</li>
<li>显示分辨率，是指整个显示器所有可视面积上水平像素和垂直像素的数量。例如800×600的分辨率，是指在整个屏幕上水平显示800个像素，垂直显示600个像素。显示器可显示的像素越多，画面就越精细，同样的屏幕区域内能显示的信息也越多，显示分辨率一定的情况下，显示屏越小图像越清晰，反之，显示屏大小固定时，显示分辨率越高图像越清晰。</li>
</ul>
]]></content>
      <categories>
        <category>计算机视觉</category>
      </categories>
      <tags>
        <tag>摄影学基础</tag>
      </tags>
  </entry>
  <entry>
    <title>HOG特征描述子原理</title>
    <url>/2021/02/25/2%E6%9C%8825%E6%97%A5%E5%B7%A5%E4%BD%9C%E6%80%BB%E7%BB%93/</url>
    <content><![CDATA[<h1 id="月25日工作总结">2月25日工作总结</h1>
]]></content>
      <categories>
        <category>工作总结</category>
      </categories>
  </entry>
</search>
